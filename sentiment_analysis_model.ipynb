{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot # visualization library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('Restaurant_Reviews.csv')\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews = reviews[reviews['Review'] != \"#NAME?\"]\n",
    "#cleaning the text\n",
    "corpus = []\n",
    "for i in range(0,1000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', reviews['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).todense()\n",
    "y = reviews.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into the training set and testset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the naive bayes model to the training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicitng the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "Confusion_Matrix = confusion_matrix(y_test, y_pred)\n",
    "Accuracy_Score = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+000, 1.00000000e+000],\n",
       "       [6.15707544e-289, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [8.58678173e-200, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [7.79455837e-299, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [2.36587144e-299, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [2.51764938e-264, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [2.10168138e-290, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [4.58097667e-320, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DIG SOME MORE TO FIND CONFIDENCE INTERVALS\n",
    "classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is : 0.725\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing the results\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "      \n",
    "df_cm = pd.DataFrame(Confusion_Matrix, range(2),\n",
    "                  range(2))\n",
    "#plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})# font size\n",
    "print(\"Accuracy Score is :\", Accuracy_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This review is:  Negative\n"
     ]
    }
   ],
   "source": [
    "#predicting a new positive review\n",
    "feedback = \"\"\n",
    "\n",
    "newReview = \"\"\n",
    "\n",
    "\n",
    "newReview = \"The food was good, but the hospitality was bad, and the air was good.\"\n",
    "\n",
    "def predict(new_review):   \n",
    "\n",
    "        new_review = re.sub(\"[^a-zA-Z]\", \" \", new_review)   \n",
    "\n",
    "        new_review = new_review.lower().split()\n",
    "\n",
    "        new_review = [ps.stem(word) for word in new_review if word not in set(stopwords.words(\"english\"))]   \n",
    "\n",
    "        new_review = \" \".join(new_review)   \n",
    "\n",
    "        new_review = [new_review]   \n",
    "\n",
    "        new_review = cv.transform(new_review).toarray()   \n",
    "\n",
    "        if classifier.predict(new_review)[0] == 1:\n",
    "\n",
    "            return \"Positive\"   \n",
    "\n",
    "        else:       \n",
    "\n",
    "            return \"Negative\"\n",
    "\n",
    "       \n",
    "\n",
    "feedback = predict(newReview)\n",
    "\n",
    "print(\"This review is: \", feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a model using scikit-learn : LOGISTIC REGRESSION\n",
    "#logistic regression is a linear model used to classify binary data\n",
    "#tutorial: https://www.twilio.com/blog/2017/12/sentiment-analysis-scikit-learn.html\n",
    "##############PREPROCESSING###############\n",
    "\n",
    "reviews_logistic = pd.read_csv('Restaurant_Reviews.csv')\n",
    "\n",
    "#vectorizing words - removing unimportant ones.\n",
    "vectorizer = CountVectorizer(analyzer = 'word', lowercase = False)\n",
    "features = vectorizer.fit_transform(reviews_logistic['Review'])\n",
    "features_nd = features.toarray()\n",
    "features_nd\n",
    "\n",
    "#test_train_split has random_state parameter: if you use random_state=some_number, \n",
    "#then you can guarantee that the output of Run 1 will be equal to the output of Run 2, \n",
    "#i.e. your split will be always the same. It doesn't matter what the actual random_state \n",
    "#number is 42, 0, 21, ... The important thing is that everytime you use 42, you will always \n",
    "#get the same output the first time you make the split. This is useful if you want \n",
    "#reproducible results, for example in the documentation, so that everybody can consistently \n",
    "#see the same numbers when they run the examples. In practice I would say, you should set the \n",
    "#random_state to some fixed number while you test stuff, but then remove it in production if \n",
    "#you really need a random (and not a fixed) split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_log, x_test_log, y_train_log, y_test_log = train_test_split(features_nd, reviews_logistic['Liked'], train_size = 0.80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=x_train_log, y = y_train_log)\n",
    "y_pred_log = log_model.predict(x_test_log)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test_log, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
